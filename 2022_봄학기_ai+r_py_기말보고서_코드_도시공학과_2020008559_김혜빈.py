# -*- coding: utf-8 -*-
"""2022_봄학기_AI+R-Py_기말보고서_코드.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dbChscteyVkr9yRtcLK8teEkYlLeRQ03
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

#다우지수 데이터 수집
url1 = "https://finance.naver.com/world/sise.naver?symbol=DJI@DJI"
response1 = requests.get(url1)
soup1 = BeautifulSoup(response1.text, 'lxml')

table1 = soup1.find('table', {'sumary':'일별시세 리스트'})

headers1=[]
for i in table1.find_all('th'):
  title1= i.get_text().strip()
  headers1.append(title1)


table_rows1 = table1.find_all('tr')

DJI = []
for tr1 in table_rows1[1:]:
    td1 = tr1.find_all('td')
    row1 = [tr1.text.strip() for tr1 in td1 if tr1.text.strip()]
    row1.append('')

    if row1:
        DJI.append(row1)

length = len(DJI)
want = []
for i in range(length):
  del DJI[i][6]
  want.append(DJI[i])

DJI_df = pd.DataFrame(DJI, columns=headers1)
DJI_df

#니케이225 데이터 수집
url2 = "https://finance.naver.com/world/sise.naver?symbol=NII@NI225"
response2 = requests.get(url2)
soup2 = BeautifulSoup(response2.text, 'lxml')

table2 = soup2.find('table', {'sumary':'일별시세 리스트'})

headers2=[]
for i in table2.find_all('th'):
  title2= i.get_text().strip()
  headers2.append(title2)


table_rows2 = table2.find_all('tr')

NI = []
for tr in table_rows2[1:]:
    td2 = tr.find_all('td')
    row2 = [tr.text.strip() for tr in td2 if tr.text.strip()]
    row2.append('')

    if row2:
        NI.append(row2)

length = len(NI)
want = []
for i in range(length):
  del NI[i][6]
  want.append(NI[i])

NI_df = pd.DataFrame(NI, columns=headers2)
NI_df

#상해종합 데이터 수집
url3 = "https://finance.naver.com/world/sise.naver?symbol=SHS@000001"
response3 = requests.get(url3)
soup3 = BeautifulSoup(response3.text, 'lxml')

table3 = soup3.find('table', {'sumary':'일별시세 리스트'})

headers3=[]
for i in table3.find_all('th'):
  title3= i.get_text().strip()
  headers3.append(title3)


table_rows3 = table3.find_all('tr')

SHS = []
for tr in table_rows3[1:]:
    td3 = tr.find_all('td')
    row3 = [tr.text.strip() for tr in td3 if tr.text.strip()]
    row3.append('')

    if row3:
        SHS.append(row3)

length = len(SHS)
want = []
for i in range(length):
  del SHS[i][6]
  want.append(SHS[i])

SHS_df = pd.DataFrame(SHS, columns=headers3)
SHS_df

#영국FTSE 데이터 수집
url5 = "https://finance.naver.com/world/sise.naver?symbol=LNS@FTSE100"
response5 = requests.get(url5)
soup5 = BeautifulSoup(response5.text, 'lxml')

table5 = soup5.find('table', {'sumary':'일별시세 리스트'})

headers5=[]
for i in table5.find_all('th'):
  title5= i.get_text().strip()
  headers5.append(title5)


table_rows5 = table5.find_all('tr')

FTSE = []
for tr in table_rows5[1:]:
    td5 = tr.find_all('td')
    row5 = [tr.text.strip() for tr in td5 if tr.text.strip()]
    row5.append('')

    if row5:
        FTSE.append(row5)

length = len(FTSE)
want = []
for i in range(length):
  del FTSE[i][6]
  want.append(FTSE[i])

FTSE_df = pd.DataFrame(FTSE, columns=headers5)
FTSE_df

#프랑스CAC 데이터 수집
url6 = "https://finance.naver.com/world/sise.naver?symbol=PAS@CAC40"
response6 = requests.get(url6)
soup6 = BeautifulSoup(response6.text, 'lxml')

table6 = soup6.find('table', {'sumary':'일별시세 리스트'})

headers6=[]
for i in table6.find_all('th'):
  title6= i.get_text().strip()
  headers6.append(title6)


table_rows6 = table6.find_all('tr')

CAC = []
for tr in table_rows6[1:]:
    td6 = tr.find_all('td')
    row6 = [tr.text.strip() for tr in td6 if tr.text.strip()]
    row6.append('')

    if row6:
        CAC.append(row6)

length = len(CAC)
want = []
for i in range(length):
  del CAC[i][6]
  want.append(CAC[i])

CAC_df = pd.DataFrame(CAC, columns=headers6)
CAC_df

#독일DAX 데이터 수집
url7 = "https://finance.naver.com/world/sise.naver?symbol=XTR@DAX30"
response7 = requests.get(url7)
soup7 = BeautifulSoup(response7.text, 'lxml')

table7 = soup7.find('table', {'sumary':'일별시세 리스트'})

headers7=[]
for i in table7.find_all('th'):
  title7= i.get_text().strip()
  headers7.append(title7)


table_rows7 = table7.find_all('tr')

DAX = []
for tr in table_rows7[1:]:
    td7 = tr.find_all('td')
    row7 = [tr.text.strip() for tr in td7 if tr.text.strip()]
    row7.append('')

    if row7:
        DAX.append(row7)

length = len(DAX)
want = []
for i in range(length):
  del DAX[i][6]
  want.append(DAX[i])

DAX_df = pd.DataFrame(DAX, columns=headers7)
DAX_df

#코스피 데이터 수집
#네이버 증권 사이트로 웹크롤링이 불가했기 때문에, 관련 csv 파일을 직접 만듦.
#제작한 csv 파일은 github에 업로드함.

KOS_df = pd.read_csv("https://raw.githubusercontent.com/hbinfromk/web/main/KOSPI_0623.csv",encoding="cp949")
KOS_df

#이용할 자료는 2022.06.16-2022.06.22임 (단, 미국의 다우지수에 06.20 자료가 없으므로, 모든 지수는 16,17,21,22일 자료만을 대상으로 함)
#각 해외 지수의 전일대비 변동 등락률을 계산

Change = pd.read_csv("https://raw.githubusercontent.com/hbinfromk/web/main/%EB%93%B1%EB%9D%BD%EB%A5%A0.csv", encoding="cp949")
Change = Change.astype('float')
Change

import numpy as np

#상관관계 출력
print(Change.corr())

#상관관계 히트맵으로 출력
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,10))
sns.heatmap(data=Change.corr(),annot=True,fmt='.2f',linewidths=1,cmap='Greens')

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

#미국 DJI지수-프랑스 CAC지수의 선형회귀 분석
lm = LinearRegression()
X=Change[['DJI']]
Y1=Change['CAC']

X_train, X_test, Y1_train, Y1_test = train_test_split(X,Y1, test_size = 0.3, random_state=0)
lm.fit(X_train,Y1_train)
yhat1=lm.predict(X_train)
pred = lm.predict(X_test)

print(mean_squared_error(Y1_test, pred))
print("절편")
print(lm.intercept_)
print("기울기")
print(lm.coef_)
print("평균 제곱 오차")
print(mean_squared_error(Y1_train,yhat1))

sns.regplot(X_train,yhat1)

#미국 DJI지수-중국 SHS지수의 선형회귀 분석
lm = LinearRegression()
X=Change[['DJI']]
Y2=Change['SHS']

X_train, X_test, Y2_train, Y2_test = train_test_split(X,Y2, test_size = 0.3, random_state=0)
lm.fit(X_train,Y2_train)
yhat2=lm.predict(X_train)
pred = lm.predict(X_test)

print(mean_squared_error(Y2_test, pred))
print("절편")
print(lm.intercept_)
print("기울기")
print(lm.coef_)
print("평균 제곱 오차")
print(mean_squared_error(Y2_train,yhat2))

sns.regplot(X_train,yhat2)

#미국 DJI지수-한국 KOSPI지수의 선형회귀 분석
lm = LinearRegression()
X=Change[['DJI']]
Y3=Change['KOS']

X_train, X_test, Y3_train, Y3_test = train_test_split(X,Y3, test_size = 0.3, random_state=0)
lm.fit(X_train,Y3_train)
yhat3=lm.predict(X_train)
pred = lm.predict(X_test)

print(mean_squared_error(Y3_test, pred))
print("절편")
print(lm.intercept_)
print("기울기")
print(lm.coef_)
print("평균 제곱 오차")
print(mean_squared_error(Y3_train,yhat3))

sns.regplot(X_train,yhat3)

#영국 FTSE지수-프랑스 CAC지수의 선형회귀 분석
lm = LinearRegression()
X1=Change[['FTSE']]
Y4=Change['CAC']

X1_train, X1_test, Y4_train, Y4_test = train_test_split(X1,Y4, test_size = 0.3, random_state=0)
lm.fit(X1_train,Y4_train)
yhat4=lm.predict(X1_train)
pred = lm.predict(X_test)

print(mean_squared_error(Y4_test, pred))
print("절편")
print(lm.intercept_)
print("기울기")
print(lm.coef_)
print("평균 제곱 오차")
print(mean_squared_error(Y4_train,yhat4))

sns.regplot(X_train,yhat4)

#일본 NI지수-중국 SHS지수의 선형회귀 분석
lm = LinearRegression()
X1=Change[['NI']]
Y5=Change['SHS']

X1_train, X1_test, Y5_train, Y5_test = train_test_split(X1,Y5, test_size = 0.3, random_state=0)
lm.fit(X1_train,Y5_train)
yhat5=lm.predict(X1_train)
pred = lm.predict(X_test)

print(mean_squared_error(Y5_test, pred))
print("절편")
print(lm.intercept_)
print("기울기")
print(lm.coef_)
print("평균 제곱 오차")
print(mean_squared_error(Y5_train,yhat5))

sns.regplot(X_train,yhat5)

